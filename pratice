Q1 :
Input: 
strore,entries
 1,p1,p2,p3,p4
 2,p1
 3,p1,p2
 4,p1,p2,p3,p4,p5,p6,p7
 
Output:
 4,7
 
Q2:
Input
RollNo, name,tamil,eng,math,sci,social 
203040, Rajesh, 10, 20, 30, 40, 50 

Output:
RollNo,name,Tamil,eng,math,sci,social ,tot
203040, Rajesh, 10, 20, 30, 40, 50,150

finally need total the sub if any one know share the code using spark scala

Q3:
Input :
Mail,mob
Renuka1992@gmail.com,9856765434 
anbu.arasu3@gmail.com,9844567788 

Output:
Mail,mob
R********2@gmail.com,98****34 
a*********3@gmail.com,98****88

Q4:
Given below is the stock data set which shows stock and its predicted price over next 7 working days/sessions As a end user i want to know what should be my buy price and what should be my sell price for each share so that i can earn maximum profit.
E.g
For RIL, if i buy it on first session and sell it on 4th session i will get 200 profit.
 
Input
StockId,PredictedPrice
RIL,[1000,1005,1090,1200,1000,900,890]
HDFC,[890,940,810,730,735,960,980]
INFY,[1001,902,1000,990,1230,1100,1200]
 
Output
StockId|BuyPrice|SellPrice|Profit
RIL|1000|1200|200
HDFC|730|980|250
INFY|902|1230|328

Q5:
ALTRIMETRIC Questios

1. what is counter mechanism
for eg u have log files didtributed u want to count only the warnings what u will do
2.
name, 			travel_location				 age
ravi			pune,delhi,chennai,noida		32
gautham			delhi,chennai				30
mary			noida,pune				35
thomas			delhi,pune				31
shankar			chennai,noida				30
find the name who have visited the places most frequently
3. I have three columns deptno,deptname and place
using scala read a text file and display only deptno and deptname. no rdds and dataframes used.

Q6:
BM Interview questions
First Scenario

EmpId    EmpName        Dept    Sal     
1        Charles        A        1000
2        Richard        A        2000
3        John        A        2000
4        Alisha        B        400
5        Robin        B        500
6        Kara        C        700
7        Natalie        D        900
8        Harry        C        600
9        Charles        D        500
10        Kate        A        1000

get 2nd highest salary

val empdata = window.partitionBy("$dept").orderBy($"sal",desc)
df.withcolumn("col3",dense_rank()over empdata).filter("col3=2")

2nd Scenario

Input
CustId    CustName    Address
1    Mark Ray        AB
2    Peter Smith        CD
1    Mark Ray        EF
2    Peter Smith        GH
2    Peter Smith        CD
3    Kate            IJ
 
Output       
CustId    CustName    AddressList
1    Mark Ray    ['AB','EF']
2    Peter Smith    ['CD','GH']
3    Kate        ['IJ']

3rd scenario
join 1st and second table. 

CustId    CustName    Address    PinCode
1        Mark         AB        123
2        Peter        CD        456
3        Kate        EF        789
PinCode    State
123        MH
456        WB


val join = df1.join(df2, seq("pincode"), "left")
join.show()

Q7:
[13:11, 5/4/2023] Apoorwa Sajjanapu D1: LTI Mindtree Interview Question Scenarios:


{
"emp":[
{
"name":"xyz",
"id":123,
"address":[
{"line1":"hyderabad","line2":"ind"},{"line1":"hyderabad"},{"line2":"ind"}]},
{"name":"abc",
"id":124,
"address":[
{"line1":"bng","line2":"ind"},{"line1":"bng"},{}]},
{"name":"jhon",
"id":125,
"address":[
{"line1":"bng","line2":"ind"},{"line1":"bng"},{}]
}
]
}





Empid, empname, salary, manager id

1 ,      xyz  ,    10000, NULL
2   ,    abc,    20000,   1
3,       fgkb,   30000,   2
4,      gfkj,    50000,   2


Populate Manager name, including all the columns
[13:11, 5/4/2023] Apoorwa Sajjanapu D1: Empid, empname, salary, manager id

1 ,      xyz  ,    10000, NULL
2   ,    abc,    20000,   1
3,       fgkb,   30000,   2
4,      gfkj,    50000,   2


Populate Manager name, including all the columns  using dataframes

Q8:
child 	parent
A 	AA
B 	BB
C 	CC
AA	AAA
BB	BBB
CC	CCC

output

child	parent	Grandparent
A	AA	AAA
B	BB	BBB
C	CC	CCC

Q9:
Write a query to find emp_id, emp_name, manager_id, manager_name 
Employee 
id, name, salary, manager_id 
1, John Smith, 10000, 3 
2, Jane Anderson, 12000, 3 
3, Tom Lanon, 15000, 4 
4, Anne Connor, 20000, NULL 
5, Jeremy York, 9000, 1

Q10:
Q: Write a query to find salary increment in the year for each employee 
employee 
employee_id,salary,year 
1,80000,2020 
1,70000,2019 
1,6000,2018 
2,65000,2020 
2,65000,2019 
2,60000,2018 
3,65000,2019 
3,60000,2018

Q11:
Orders.csv
order_id,item,amount,customer_id 
1,Keyboard,400,4 
2,Mouse,300,4 
3,Monitor,12000,3 
4,Keyboard,400,1 
5,Mousepad,250,2
 
Customers.txt
customer_id|^|first_name|^|last_name|^|age|^|country|^|monthly_salary 
1|^|John|^|Doe|^|31|^|USA|^|1000 
2|^|Robert|^|Luna|^|22|^|USA|^|2000 
3|^|David|^|Robinson|^|22|^|UK|^|2500 
4|^|John|^|Reinhardt|^|25|^|UK|^|1500 
5|^|Betty|^|Doe|^|28|^|UAE|^|1200

Q12:
Find below expected output through spark and scala
sensorid timestamp values
11111 2021-01-15 10
11111 2021-01-16 15
11111 2021-01-17 30
11112 2021-01-15 10
11112 2021-01-16 20
11112 2021-01-17 30
 
 
Output :
sensorid timestamp values
11111 2021-01-15 05
11111 2021-01-16 15
11112 2021-01-15 10
11112 2021-01-16 10

Q13:
Consider the Employee table below.
 
Emp_Id   Emp_name    Salary    Manager_Id
10       Anil         50000    18
11       Vikas        75000    16
12       Nisha        40000    18
13       Nidhi        60000    17
14       Priya        80000    18
15       Mohit        45000    18
16       Rajesh       90000    16
17       Raman        55000    16
18       Santosh      65000    17

Write a query to generate below output:
 
Manager_Id    Manager    Average_Salary_Under_Manager
16            Rajesh            65000
17            Raman             62500
18            Santosh           53750

Q14:
Input

1
01
011
0111
01111 



Output

00001
00001
00011
00111

Q15:
SQL SCENARIO


WORKER_ID	FIRST_NAME	LAST_NAME	SALARY	JOINING_DATE	DEPARTMENT
001	Monika	Arora	100000	2014-02-20 09:00:00	HR
002	Niharika	Verma	300000	2014-06-11 09:00:00	Admin
003	Vishal	Singhal	300000	2014-02-20 09:00:00	HR
004	Amitabh	Singh	500000	2014-02-20 09:00:00	Admin
005	Vivek	Bhati	500000	2014-06-11 09:00:00	Admin

query: To get who are getting equal salary




Order_id      status_date     status
1            1-Jan            Ordered
1            2-Jan            dispatched
1            3-Jan            dispatched
1            4-Jan            Shipped
1            5-Jan            Shipped
1            6-Jan            Delivered
2            1-Jan            Ordered
2            2-Jan            dispatched
2            3-Jan            shipped

Need the dates whenthe status gets changed like ordered to dispatched

Q16:
input: aabbccabca
output: a2b2c2a1b1c1a1

write a code in scala??

Q17:
Apexon Interview Questions: 1. I have same values in table a and table b
what is the output of inner and full outerjoin?  
1
2
3
1
2
1

SQL
==== 
​2. Input
======
Emp_Id,Emp_name,Salary,Manager_Id
1,A,50000,9
2,B,75000,7
3,C,40000,9
4,D,60000,8
5,E,80000,9
6,F,45000,9
7,G,90000,–
8,H,55000,7
9,I,65000,8
 

Output:
=========
Manager_Id    Manager_Name Average_Salary_Under_Manager
7    G    65000
8    H    62500
9    I    53750


3. In SQL or Spark SQL(anyone fine)
Input:
======
Id, TeamName
1, India
2, Australia
3, England
4, New Zealand

Output:
========
India vs Australia
India vs England
India vs New Zealand
Australia vs England
Australia vs New Zealand
England vs New Zealand
 


In Python(not pyspark):
==========
Input:
=======
list1= ["ind", "aus", "eng", "nz"]

=======
Output:
========
India vs Australia
India vs England
India vs New Zealand
Australia vs England
Australia vs New Zealand
England vs New Zealand



Spark
======
df1 contains Employeeid,Name,Age,State,Country columns
   df2 contains Employeeid,Name,Age,Address columns.
   how do you merge df1 and df2 to get the following output?
   Employeeid,Name,Age,State,Country,Address
   
Q20:
 select missing numbers in Table Numbers. The gap will be always of 1 and numbers can be from 0 to infinity.
CREATE TABLE Numbers (number INT NOT Null);
insert into Numbers  values (1),(2),(4),(5),(7),(9),(11);

Q21:
# Q2 - Write a sql query to find source and destination of each airway, output is given right side
Create table flight
(id int,
airway varchar (50),
src varchar (50),
dest varchar (50));

Insert into flight 
(id, airway, src, dest)
Values
(1,	'Indigo', 'India', 'Bhutan' ),
(2,	'Air Asia', 'Aus', 'India'),
(3,	'Indigo', 'Bhutan', 'Nepal'),
(4,	'spice jet', 'SriLanka', 'Bhutan'),
(5,	'Indigo', 'Nepal', 'SriLanka'),
(6,	'Air Asia', 'India', 'Japan'),
(7,	'spice jet', 'Bhutan', 'Nepal');


## output
# Flight		 Source  	 Destination
# Indigo		 India   	 Srilanka
# Air Asia  	 Aus 		 Japan
# spice jet 	 SriLanka    Nepal

Q22:
- List all the employee as the First Name & last L Name as full Name, return the DepartmentId if ManagerId ID is null, else return the ManagerId of the employee. There should be a first hire date column also whose value will be first hire_date of department to which the employee belongs to.
CREATE TABLE Departments (
    Id INT NOT NULL AUTO_INCREMENT,# Q3 -From the Items table containing a list of dates and items ordered, write a query to return the most frequent item ordered on each date. Return multiple items in the case of a tie.
CREATE TABLE Items (
	Id INT NOT Null AUTO_INCREMENT,
    dated DATE NOT NULL,
  	item VARCHAR(25) NOT NULL,
  	PRIMARY KEY(Id)
);



INSERT INTO Items 
	(dated, item)
VALUES
	(STR_TO_DATE('01-01-2020','%m-%d-%Y'), 'apple'),
    (STR_TO_DATE('01-01-2020','%m-%d-%Y'), 'apple'),
    (STR_TO_DATE('01-01-2020','%m-%d-%Y'), 'pear'),
    (STR_TO_DATE('01-01-2020','%m-%d-%Y'), 'pear'),
    (STR_TO_DATE('01-02-2020','%m-%d-%Y'), 'pear'),
    (STR_TO_DATE('01-02-2020','%m-%d-%Y'), 'pear'),
    (STR_TO_DATE('01-02-2020','%m-%d-%Y'), 'pear'),
    (STR_TO_DATE('01-02-2020','%m-%d-%Y'), 'orange'),
    (STR_TO_DATE('01-03-2020', '%m-%d-%Y'), 'Banana')
    ;
    Name VARCHAR(25) NOT NULL,
    PRIMARY KEY(Id)
);


CREATE TABLE Employees (
    Id INT NOT NULL AUTO_INCREMENT,
    FName VARCHAR(35) NOT NULL,
    LName VARCHAR(35) NOT NULL,
    PhoneNumber VARCHAR(11),
    ManagerId INT,
    DepartmentId INT NOT NULL,
    Salary INT NOT NULL,
    HireDate DATETIME NOT NULL,
    PRIMARY KEY(Id),
    FOREIGN KEY (ManagerId) REFERENCES Employees(Id),
    FOREIGN KEY (DepartmentId) REFERENCES Departments(Id)
);

INSERT INTO Departments
    (Id, Name)
VALUES
    (1, 'HR'),
    (2, 'Sales'),
    (3, 'Tech')
;

INSERT INTO Employees
    (Id, FName, LName, PhoneNumber, ManagerId, DepartmentId, Salary, HireDate)
VALUES
    (1, 'James', 'Smith', 1234567890, NULL, 1, 13000, str_to_date('01-01-2002', '%d-%m-%Y')),
    (2, 'John', 'Johnson', 2468101214, '1', 3, 400, str_to_date('23-03-2005', '%d-%m-%Y')),
    (3, 'Michael', 'Williams', 1357911131, '1', 2, 16000, str_to_date('12-05-2009', '%d-%m-%Y')),
    (4, 'John', 'Smith', 1212121212, '2', 1, 500, str_to_date('24-07-2016', '%d-%m-%Y')),
    (5, 'James', 'Williams', 1234567891, NULL, 1, 5000, str_to_date('01-01-2012', '%d-%m-%Y')),
    (6, 'John', 'Williams', 2468101212, '3', 1, 3400, str_to_date('23-03-2015', '%d-%m-%Y')),
    (7, 'Smith', 'Williams', 1357911133, '4', 2, 6700, str_to_date('12-05-2019', '%d-%m-%Y')),
    (8, 'Michael', 'Smith', 1212121214, '2', 3, 1500, str_to_date('24-07-2006', '%d-%m-%Y')),
    (9, 'Michael', 'Johnson', 1357911135, '1', 2, 600, str_to_date('12-05-2009', '%d-%m-%Y')),
    (10, 'Johnathon', 'Smith', 1212121216, '2', 1, 2500, str_to_date('24-07-2020', '%d-%m-%Y'))
;



Q23:
Input
=====

Id   formula   value 
1     1+4           10      
2      2-3            30
3      2+4           50
4      2+1           40



Output:
======
Output
50
-20
70
40

Q24:
 Scala Spark

INPUT      ==>     ("Hello World")

i want output as

OUTPUT   ==>     ("olleH dlroW")

Q25:
